{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Najważniejszą rzeczą do zrozumienia jest to, że ten kod w rzeczywistości nie wykonuje żadnych obliczeń, nawet jeśli wygląda na to (szczególnie na ostatniej linii). Po prostu tworzy graf obliczeniowy. \n",
    "\n",
    "W rzeczywistości nawet zmienne nie zostały jeszcze zainicjowane. Aby wykonać ten graf, należy otworzyć sesję TensorFlow i użyć jej do zainicjowania zmiennych i wyliczenia $f$. \n",
    "\n",
    "Sesja TensorFlow zajmuje się umieszczaniem operacji na urządzeniach takich jak procesory i GPU oraz ich uruchomieniem i przechowuje wszystkie wartości zmiennych:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciągłe powtarzanie sesji **sess.run()** jest nieco uciążliwe, ale na szczęście jest lepszy sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast ręcznie uruchamiać inicjalizator dla każdej zmiennej, można użyć skrótu\n",
    "Funkcja **global_variables_initializer()**. Zauważ, że nie wykonuje on natychmiastowej nitlizacji, lecz tworzy na wykresie węzeł, który inicjalizuje wszystkie zmienne podczas działania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program TensorFlow dzieli się zazwyczaj na dwie części: pierwsza część tworzy graf obliczeniowy (nazywa się to fazą konstrukcyjną), a druga część uruchamia go (jest to faza wykonania)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzeniw grfów\n",
    "Każdy utworzony węzeł jest automatycznie dodawany do domyślnego grafu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W większości przypadków jest to w porządku, ale czasami możesz chcieć zarządzać wieloma niezależnymi grafami. Możesz to zrobić, tworząc nowy graf i tymczasowo ustawiając go jako domyślny wykres wewnątrz bloku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Jupyter (lub w powłoce Pythona) często używa się tych samych poleceń więcej niż raz podczas eksperymentowania. W rezultacie może pojawić się domyślny wykres zawierający wiele zduplikowanych węzłów. Jednym z rozwiązań jest ponowne uruchomienie jądra Jupytera (lub powłoki Pythona), ale wygodniejszym rozwiązaniem jest przywrócenie domyślnego wykresu poprzez uruchomienie **tf.reset_default_graph()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podczas inicjalizacji węzła TensorFlow automatycznie określa zestaw węzłów, od których zależy i najpierw inicjalizuje te węzły. Rozważmy na przykład następujący kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) \n",
    "    print(z.eval()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weźmy dane housing oraz wykonajmy regresję liniową za pomocą rozwiązania układu równań liniowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "print(m, n)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "housing_data_scaled=scaler.fit_transform(housing.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą NumPy wyglądało by to tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing_data_scaled]\n",
    "print(housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Za pomocą Scikit-Learn można to zrobić tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_data_scaled, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tensorflow możemy to zrobić tak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06856298]\n",
      " [ 0.82961965]\n",
      " [ 0.11875178]\n",
      " [-0.26552707]\n",
      " [ 0.30569667]\n",
      " [-0.00450281]\n",
      " [-0.03932635]\n",
      " [-0.8998825 ]\n",
      " [-0.87053877]]\n"
     ]
    }
   ],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje na poniższych danych oraz narysuj wykres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20dccb6ed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "data = np.loadtxt(\"life_satisfaction.csv\",\n",
    "                  dtype=np.float32,\n",
    "                  delimiter=\",\",\n",
    "                  skiprows=1,\n",
    "                  usecols=[1, 2])\n",
    "X_train = data[:, 0:1] / 10000 # feature scaling\n",
    "y_train = data[:, 1:2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20dcf84d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "Możemy zminimalizować funkcję kosztu gradientowo wykorzystując gradient:\n",
    "```python\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "[[  2.06855226e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845096e-01]\n",
      " [  1.64778158e-01]\n",
      " [  7.44080753e-04]\n",
      " [ -3.91945168e-02]\n",
      " [ -8.61356616e-01]\n",
      " [ -8.23479712e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też użyć gradientu wyliczonego za pomocą automatycznego różniczkowania\n",
    "```python\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciekwaostka\n",
    "\n",
    "Jak można znaleźć pochodne czaskowe poniższej funkcji w odniesieniu do a i b?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z\n",
    "\n",
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.212537\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimizer\n",
    "\n",
    "Możemy również użyć wbudowanej funkcji do optymalizacji\n",
    "\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest wiele różnych metod optymalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warstwa typu placeholder\n",
    "Warstwa typu placeholder pozwala na dynamiczne dostarczanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "W naszym przypadku mamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.07001591]\n",
      " [ 0.82045609]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.31134021]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.87950081]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size)  \n",
    "    X_batch = housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "print(\"Best theta:\")\n",
    "print(best_theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.07001591]\n",
      " [ 0.82045609]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.31134021]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.87950081]]\n"
     ]
    }
   ],
   "source": [
    "print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbudujmy prostą sieć neuronową"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy dane w kształcie księżyców"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "data_X, data_y = sklearn.datasets.make_moons(n_samples=1000, noise=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprostszym sposobem nauczenia MLP za pomocą TensorFlow jest wykorzystanie API wysokiego poziomu **TF.Learn**, który jest dość podobny do API Scikit-Learn. \n",
    "\n",
    "Klasa DNNClassifier ułatwia nauczanie głębokiej sieci neuronowej z dowolną liczbą ukrytych warstw i warstwą wyjściową softmax. \n",
    "\n",
    "Na przykład poniższy kod uczy DNN do klasyfikacji z dwiema ukrytymi warstwami (jedną z 300 neuronami, a drugą ze 100 neuronami) i warstwą wyjściową softmax z 10 neuronami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\przem85\\AppData\\Local\\Temp\\tmpoga7q041\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_evaluation_master': '', '_num_ps_replicas': 0, '_task_type': None, '_session_config': None, '_is_chief': True, '_task_id': 0, '_tf_random_seed': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020DD892A908>, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_model_dir': 'C:\\\\Users\\\\przem85\\\\AppData\\\\Local\\\\Temp\\\\tmpoga7q041'}\n",
      "WARNING:tensorflow:From <ipython-input-102-5805a979ac18>:6: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-102-5805a979ac18>:6: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-102-5805a979ac18>:6: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\przem85\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\przem85\\AppData\\Local\\Temp\\tmpoga7q041\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.33415\n",
      "INFO:tensorflow:global_step/sec: 397.346\n",
      "INFO:tensorflow:step = 101, loss = 0.207209 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:step = 201, loss = 0.121151 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:step = 301, loss = 0.0751764 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.817\n",
      "INFO:tensorflow:step = 401, loss = 0.0366008 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.425\n",
      "INFO:tensorflow:step = 501, loss = 0.038142 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:step = 601, loss = 0.00894693 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.601\n",
      "INFO:tensorflow:step = 701, loss = 0.00505226 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.887\n",
      "INFO:tensorflow:step = 801, loss = 0.00288534 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.424\n",
      "INFO:tensorflow:step = 901, loss = 0.00427873 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.75\n",
      "INFO:tensorflow:step = 1001, loss = 0.00598491 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:step = 1101, loss = 0.00239675 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:step = 1201, loss = 0.00140298 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.042\n",
      "INFO:tensorflow:step = 1301, loss = 0.00295205 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.152\n",
      "INFO:tensorflow:step = 1401, loss = 0.0014889 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.937\n",
      "INFO:tensorflow:step = 1501, loss = 0.00147934 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.354\n",
      "INFO:tensorflow:step = 1601, loss = 0.0019783 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.836\n",
      "INFO:tensorflow:step = 1701, loss = 0.00191677 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.423\n",
      "INFO:tensorflow:step = 1801, loss = 0.00122734 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.523\n",
      "INFO:tensorflow:step = 1901, loss = 0.000971739 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.846\n",
      "INFO:tensorflow:step = 2001, loss = 0.00200561 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.596\n",
      "INFO:tensorflow:step = 2101, loss = 0.0008571 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.43\n",
      "INFO:tensorflow:step = 2201, loss = 0.00126603 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.538\n",
      "INFO:tensorflow:step = 2301, loss = 0.00114214 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.565\n",
      "INFO:tensorflow:step = 2401, loss = 0.000424342 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.882\n",
      "INFO:tensorflow:step = 2501, loss = 0.00139831 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.222\n",
      "INFO:tensorflow:step = 2601, loss = 0.00217507 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.122\n",
      "INFO:tensorflow:step = 2701, loss = 0.000556518 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.357\n",
      "INFO:tensorflow:step = 2801, loss = 0.00156624 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.06\n",
      "INFO:tensorflow:step = 2901, loss = 0.000880983 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.069\n",
      "INFO:tensorflow:step = 3001, loss = 0.000513878 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:step = 3101, loss = 0.000374778 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:step = 3201, loss = 0.000944243 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.75\n",
      "INFO:tensorflow:step = 3301, loss = 0.00130796 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.668\n",
      "INFO:tensorflow:step = 3401, loss = 0.000497826 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.05\n",
      "INFO:tensorflow:step = 3501, loss = 0.000542224 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.34\n",
      "INFO:tensorflow:step = 3601, loss = 0.000370728 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.948\n",
      "INFO:tensorflow:step = 3701, loss = 0.000683257 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.614\n",
      "INFO:tensorflow:step = 3801, loss = 0.000177141 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.417\n",
      "INFO:tensorflow:step = 3901, loss = 0.000400462 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.773\n",
      "INFO:tensorflow:step = 4001, loss = 0.000323469 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.891\n",
      "INFO:tensorflow:step = 4101, loss = 0.000227212 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.073\n",
      "INFO:tensorflow:step = 4201, loss = 0.000204797 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.888\n",
      "INFO:tensorflow:step = 4301, loss = 0.000255698 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.044\n",
      "INFO:tensorflow:step = 4401, loss = 0.00164087 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.262\n",
      "INFO:tensorflow:step = 4501, loss = 0.000252154 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.566\n",
      "INFO:tensorflow:step = 4601, loss = 0.00018531 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.603\n",
      "INFO:tensorflow:step = 4701, loss = 0.0002426 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.422\n",
      "INFO:tensorflow:step = 4801, loss = 0.000497127 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.356\n",
      "INFO:tensorflow:step = 4901, loss = 0.000397425 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.627\n",
      "INFO:tensorflow:step = 5001, loss = 0.000163173 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.078\n",
      "INFO:tensorflow:step = 5101, loss = 0.00103811 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.745\n",
      "INFO:tensorflow:step = 5201, loss = 0.000165985 (0.247 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 417.298\n",
      "INFO:tensorflow:step = 5301, loss = 0.000225699 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.397\n",
      "INFO:tensorflow:step = 5401, loss = 0.000195054 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.266\n",
      "INFO:tensorflow:step = 5501, loss = 8.04274e-05 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.238\n",
      "INFO:tensorflow:step = 5601, loss = 0.000197051 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.279\n",
      "INFO:tensorflow:step = 5701, loss = 0.000139565 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.258\n",
      "INFO:tensorflow:step = 5801, loss = 0.00023838 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.584\n",
      "INFO:tensorflow:step = 5901, loss = 0.000123051 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.3\n",
      "INFO:tensorflow:step = 6001, loss = 0.000183859 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.073\n",
      "INFO:tensorflow:step = 6101, loss = 0.000134788 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:step = 6201, loss = 0.000148669 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.019\n",
      "INFO:tensorflow:step = 6301, loss = 0.000498174 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.658\n",
      "INFO:tensorflow:step = 6401, loss = 0.000800169 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.428\n",
      "INFO:tensorflow:step = 6501, loss = 0.000120325 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:step = 6601, loss = 0.000307776 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.43\n",
      "INFO:tensorflow:step = 6701, loss = 0.000420067 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.153\n",
      "INFO:tensorflow:step = 6801, loss = 0.000176995 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.276\n",
      "INFO:tensorflow:step = 6901, loss = 0.000181881 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.911\n",
      "INFO:tensorflow:step = 7001, loss = 0.000569893 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.749\n",
      "INFO:tensorflow:step = 7101, loss = 8.68721e-05 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.759\n",
      "INFO:tensorflow:step = 7201, loss = 0.000252769 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.049\n",
      "INFO:tensorflow:step = 7301, loss = 0.000252894 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.548\n",
      "INFO:tensorflow:step = 7401, loss = 8.31681e-05 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.439\n",
      "INFO:tensorflow:step = 7501, loss = 0.000105371 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.421\n",
      "INFO:tensorflow:step = 7601, loss = 0.000257007 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.243\n",
      "INFO:tensorflow:step = 7701, loss = 0.00012239 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:step = 7801, loss = 0.00027345 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.405\n",
      "INFO:tensorflow:step = 7901, loss = 0.000343407 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "INFO:tensorflow:step = 8001, loss = 0.000106236 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.4\n",
      "INFO:tensorflow:step = 8101, loss = 0.000254523 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.24\n",
      "INFO:tensorflow:step = 8201, loss = 0.00015812 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.123\n",
      "INFO:tensorflow:step = 8301, loss = 0.000237874 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.892\n",
      "INFO:tensorflow:step = 8401, loss = 0.000234891 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:step = 8501, loss = 0.000316896 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.745\n",
      "INFO:tensorflow:step = 8601, loss = 4.70247e-05 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.296\n",
      "INFO:tensorflow:step = 8701, loss = 0.000798544 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.356\n",
      "INFO:tensorflow:step = 8801, loss = 4.89117e-05 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.537\n",
      "INFO:tensorflow:step = 8901, loss = 0.00021485 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.424\n",
      "INFO:tensorflow:step = 9001, loss = 0.000232284 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.664\n",
      "INFO:tensorflow:step = 9101, loss = 7.93559e-05 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.415\n",
      "INFO:tensorflow:step = 9201, loss = 0.000126394 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.273\n",
      "INFO:tensorflow:step = 9301, loss = 8.20827e-05 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.94\n",
      "INFO:tensorflow:step = 9401, loss = 0.000107196 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.602\n",
      "INFO:tensorflow:step = 9501, loss = 7.30836e-05 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.52\n",
      "INFO:tensorflow:step = 9601, loss = 0.00024704 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.213\n",
      "INFO:tensorflow:step = 9701, loss = 0.000164711 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.557\n",
      "INFO:tensorflow:step = 9801, loss = 5.42029e-05 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.24\n",
      "INFO:tensorflow:step = 9901, loss = 0.00027149 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.745\n",
      "INFO:tensorflow:step = 10001, loss = 7.03785e-05 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.827\n",
      "INFO:tensorflow:step = 10101, loss = 0.000242046 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:step = 10201, loss = 6.80244e-05 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.782\n",
      "INFO:tensorflow:step = 10301, loss = 0.000278137 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.25\n",
      "INFO:tensorflow:step = 10401, loss = 8.31915e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.299\n",
      "INFO:tensorflow:step = 10501, loss = 1.32342e-05 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.566\n",
      "INFO:tensorflow:step = 10601, loss = 0.000250921 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.353\n",
      "INFO:tensorflow:step = 10701, loss = 4.9518e-05 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.207\n",
      "INFO:tensorflow:step = 10801, loss = 0.000205782 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.327\n",
      "INFO:tensorflow:step = 10901, loss = 0.000338619 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.67\n",
      "INFO:tensorflow:step = 11001, loss = 0.000236728 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.111\n",
      "INFO:tensorflow:step = 11101, loss = 0.000211512 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.322\n",
      "INFO:tensorflow:step = 11201, loss = 0.000234735 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.511\n",
      "INFO:tensorflow:step = 11301, loss = 0.000138685 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.191\n",
      "INFO:tensorflow:step = 11401, loss = 8.6103e-05 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.069\n",
      "INFO:tensorflow:step = 11501, loss = 0.000395278 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.098\n",
      "INFO:tensorflow:step = 11601, loss = 0.000111722 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.015\n",
      "INFO:tensorflow:step = 11701, loss = 5.27946e-05 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.122\n",
      "INFO:tensorflow:step = 11801, loss = 6.29273e-05 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.145\n",
      "INFO:tensorflow:step = 11901, loss = 0.000103949 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.593\n",
      "INFO:tensorflow:step = 12001, loss = 8.52831e-05 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.926\n",
      "INFO:tensorflow:step = 12101, loss = 8.12842e-05 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.842\n",
      "INFO:tensorflow:step = 12201, loss = 0.000118601 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.046\n",
      "INFO:tensorflow:step = 12301, loss = 0.000224416 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.082\n",
      "INFO:tensorflow:step = 12401, loss = 0.000137155 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.781\n",
      "INFO:tensorflow:step = 12501, loss = 0.000349394 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.94\n",
      "INFO:tensorflow:step = 12601, loss = 0.000106344 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.068\n",
      "INFO:tensorflow:step = 12701, loss = 0.000143875 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.567\n",
      "INFO:tensorflow:step = 12801, loss = 0.000220042 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.113\n",
      "INFO:tensorflow:step = 12901, loss = 0.00014929 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.114\n",
      "INFO:tensorflow:step = 13001, loss = 0.000105512 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.688\n",
      "INFO:tensorflow:step = 13101, loss = 0.000102275 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.77\n",
      "INFO:tensorflow:step = 13201, loss = 8.52622e-05 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.77\n",
      "INFO:tensorflow:step = 13301, loss = 0.000365907 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 13401, loss = 3.44799e-05 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.755\n",
      "INFO:tensorflow:step = 13501, loss = 0.000103344 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.142\n",
      "INFO:tensorflow:step = 13601, loss = 8.50163e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.359\n",
      "INFO:tensorflow:step = 13701, loss = 3.8125e-05 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.819\n",
      "INFO:tensorflow:step = 13801, loss = 0.000284931 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.07\n",
      "INFO:tensorflow:step = 13901, loss = 4.95352e-05 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.115\n",
      "INFO:tensorflow:step = 14001, loss = 5.00989e-05 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.021\n",
      "INFO:tensorflow:step = 14101, loss = 4.73346e-05 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:step = 14201, loss = 4.42539e-05 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.911\n",
      "INFO:tensorflow:step = 14301, loss = 5.5443e-05 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.316\n",
      "INFO:tensorflow:step = 14401, loss = 0.000155195 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.138\n",
      "INFO:tensorflow:step = 14501, loss = 4.24064e-05 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.941\n",
      "INFO:tensorflow:step = 14601, loss = 2.48211e-05 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.508\n",
      "INFO:tensorflow:step = 14701, loss = 5.26614e-05 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.721\n",
      "INFO:tensorflow:step = 14801, loss = 8.77581e-05 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.78\n",
      "INFO:tensorflow:step = 14901, loss = 7.70495e-05 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.559\n",
      "INFO:tensorflow:step = 15001, loss = 3.70702e-05 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.244\n",
      "INFO:tensorflow:step = 15101, loss = 4.83264e-05 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.301\n",
      "INFO:tensorflow:step = 15201, loss = 6.92011e-05 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.688\n",
      "INFO:tensorflow:step = 15301, loss = 0.000177573 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.708\n",
      "INFO:tensorflow:step = 15401, loss = 2.94249e-05 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.5\n",
      "INFO:tensorflow:step = 15501, loss = 3.76594e-05 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.756\n",
      "INFO:tensorflow:step = 15601, loss = 7.40723e-05 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.146\n",
      "INFO:tensorflow:step = 15701, loss = 4.91575e-05 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.42\n",
      "INFO:tensorflow:step = 15801, loss = 9.79877e-05 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.605\n",
      "INFO:tensorflow:step = 15901, loss = 3.49716e-05 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.71\n",
      "INFO:tensorflow:step = 16001, loss = 0.000328497 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.359\n",
      "INFO:tensorflow:step = 16101, loss = 1.96439e-05 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.336\n",
      "INFO:tensorflow:step = 16201, loss = 0.000180073 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.401\n",
      "INFO:tensorflow:step = 16301, loss = 7.99201e-05 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.145\n",
      "INFO:tensorflow:step = 16401, loss = 9.001e-05 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.808\n",
      "INFO:tensorflow:step = 16501, loss = 3.88145e-05 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.992\n",
      "INFO:tensorflow:step = 16601, loss = 3.881e-05 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.774\n",
      "INFO:tensorflow:step = 16701, loss = 3.34385e-05 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.143\n",
      "INFO:tensorflow:step = 16801, loss = 2.80028e-05 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.404\n",
      "INFO:tensorflow:step = 16901, loss = 2.19546e-05 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.866\n",
      "INFO:tensorflow:step = 17001, loss = 3.77133e-05 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.732\n",
      "INFO:tensorflow:step = 17101, loss = 0.000122539 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.406\n",
      "INFO:tensorflow:step = 17201, loss = 0.000104404 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.689\n",
      "INFO:tensorflow:step = 17301, loss = 2.24335e-05 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.875\n",
      "INFO:tensorflow:step = 17401, loss = 6.2813e-05 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.94\n",
      "INFO:tensorflow:step = 17501, loss = 4.3068e-05 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.662\n",
      "INFO:tensorflow:step = 17601, loss = 3.77354e-05 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.929\n",
      "INFO:tensorflow:step = 17701, loss = 4.92662e-05 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.77\n",
      "INFO:tensorflow:step = 17801, loss = 2.0538e-05 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.495\n",
      "INFO:tensorflow:step = 17901, loss = 0.000156573 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.07\n",
      "INFO:tensorflow:step = 18001, loss = 4.26121e-05 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.812\n",
      "INFO:tensorflow:step = 18101, loss = 3.88041e-05 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.493\n",
      "INFO:tensorflow:step = 18201, loss = 0.000120761 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.196\n",
      "INFO:tensorflow:step = 18301, loss = 3.77099e-05 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 382.124\n",
      "INFO:tensorflow:step = 18401, loss = 5.89516e-05 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.746\n",
      "INFO:tensorflow:step = 18501, loss = 5.77638e-05 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.938\n",
      "INFO:tensorflow:step = 18601, loss = 5.46432e-05 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.286\n",
      "INFO:tensorflow:step = 18701, loss = 8.63314e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.517\n",
      "INFO:tensorflow:step = 18801, loss = 2.97569e-05 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.942\n",
      "INFO:tensorflow:step = 18901, loss = 7.17654e-05 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.585\n",
      "INFO:tensorflow:step = 19001, loss = 4.2144e-05 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.327\n",
      "INFO:tensorflow:step = 19101, loss = 3.87394e-05 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.124\n",
      "INFO:tensorflow:step = 19201, loss = 9.37029e-05 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.443\n",
      "INFO:tensorflow:step = 19301, loss = 0.000103662 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.946\n",
      "INFO:tensorflow:step = 19401, loss = 6.16656e-05 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.754\n",
      "INFO:tensorflow:step = 19501, loss = 3.76704e-05 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.919\n",
      "INFO:tensorflow:step = 19601, loss = 4.73115e-05 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.609\n",
      "INFO:tensorflow:step = 19701, loss = 8.50861e-05 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.406\n",
      "INFO:tensorflow:step = 19801, loss = 0.000133069 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.623\n",
      "INFO:tensorflow:step = 19901, loss = 5.08849e-05 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.809\n",
      "INFO:tensorflow:step = 20001, loss = 0.000173178 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.889\n",
      "INFO:tensorflow:step = 20101, loss = 0.000138471 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.558\n",
      "INFO:tensorflow:step = 20201, loss = 0.000123488 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.604\n",
      "INFO:tensorflow:step = 20301, loss = 3.20583e-05 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.423\n",
      "INFO:tensorflow:step = 20401, loss = 0.000137123 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.923\n",
      "INFO:tensorflow:step = 20501, loss = 0.000153798 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.029\n",
      "INFO:tensorflow:step = 20601, loss = 2.86313e-05 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.164\n",
      "INFO:tensorflow:step = 20701, loss = 0.000109556 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.936\n",
      "INFO:tensorflow:step = 20801, loss = 3.6815e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.016\n",
      "INFO:tensorflow:step = 20901, loss = 2.5528e-05 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.747\n",
      "INFO:tensorflow:step = 21001, loss = 0.00011046 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.072\n",
      "INFO:tensorflow:step = 21101, loss = 0.000126137 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.656\n",
      "INFO:tensorflow:step = 21201, loss = 6.81368e-05 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.594\n",
      "INFO:tensorflow:step = 21301, loss = 6.5726e-05 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.71\n",
      "INFO:tensorflow:step = 21401, loss = 0.000120617 (0.389 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 335.805\n",
      "INFO:tensorflow:step = 21501, loss = 0.000144276 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.154\n",
      "INFO:tensorflow:step = 21601, loss = 9.22654e-06 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.08\n",
      "INFO:tensorflow:step = 21701, loss = 3.64299e-05 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.05\n",
      "INFO:tensorflow:step = 21801, loss = 2.89953e-05 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.553\n",
      "INFO:tensorflow:step = 21901, loss = 3.20114e-05 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.94\n",
      "INFO:tensorflow:step = 22001, loss = 2.19647e-05 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.523\n",
      "INFO:tensorflow:step = 22101, loss = 9.69435e-05 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.731\n",
      "INFO:tensorflow:step = 22201, loss = 3.82988e-05 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:step = 22301, loss = 1.58896e-05 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.194\n",
      "INFO:tensorflow:step = 22401, loss = 5.00574e-05 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.3\n",
      "INFO:tensorflow:step = 22501, loss = 8.90604e-05 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.917\n",
      "INFO:tensorflow:step = 22601, loss = 7.34789e-05 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.897\n",
      "INFO:tensorflow:step = 22701, loss = 3.24025e-05 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.492\n",
      "INFO:tensorflow:step = 22801, loss = 2.80932e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.496\n",
      "INFO:tensorflow:step = 22901, loss = 2.11861e-05 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.889\n",
      "INFO:tensorflow:step = 23001, loss = 2.02107e-05 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.051\n",
      "INFO:tensorflow:step = 23101, loss = 7.68712e-05 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.771\n",
      "INFO:tensorflow:step = 23201, loss = 0.000126156 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.139\n",
      "INFO:tensorflow:step = 23301, loss = 3.01023e-05 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.539\n",
      "INFO:tensorflow:step = 23401, loss = 4.86289e-05 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.76\n",
      "INFO:tensorflow:step = 23501, loss = 2.64695e-05 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.993\n",
      "INFO:tensorflow:step = 23601, loss = 1.57301e-05 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.141\n",
      "INFO:tensorflow:step = 23701, loss = 4.18101e-05 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.217\n",
      "INFO:tensorflow:step = 23801, loss = 5.34996e-05 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.94\n",
      "INFO:tensorflow:step = 23901, loss = 0.000104209 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.422\n",
      "INFO:tensorflow:step = 24001, loss = 1.64233e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.261\n",
      "INFO:tensorflow:step = 24101, loss = 3.6524e-05 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.408\n",
      "INFO:tensorflow:step = 24201, loss = 1.38851e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.284\n",
      "INFO:tensorflow:step = 24301, loss = 0.000156453 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.495\n",
      "INFO:tensorflow:step = 24401, loss = 3.30565e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.409\n",
      "INFO:tensorflow:step = 24501, loss = 0.000173735 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.834\n",
      "INFO:tensorflow:step = 24601, loss = 9.24477e-05 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.239\n",
      "INFO:tensorflow:step = 24701, loss = 2.45973e-05 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.878\n",
      "INFO:tensorflow:step = 24801, loss = 0.000135726 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.731\n",
      "INFO:tensorflow:step = 24901, loss = 5.83227e-05 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.286\n",
      "INFO:tensorflow:step = 25001, loss = 3.0446e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:step = 25101, loss = 3.31609e-05 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.602\n",
      "INFO:tensorflow:step = 25201, loss = 1.8164e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.88\n",
      "INFO:tensorflow:step = 25301, loss = 0.000195292 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.405\n",
      "INFO:tensorflow:step = 25401, loss = 0.000103141 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.347\n",
      "INFO:tensorflow:step = 25501, loss = 1.67385e-05 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.748\n",
      "INFO:tensorflow:step = 25601, loss = 1.38826e-05 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.43\n",
      "INFO:tensorflow:step = 25701, loss = 1.83382e-05 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.626\n",
      "INFO:tensorflow:step = 25801, loss = 7.90582e-06 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.076\n",
      "INFO:tensorflow:step = 25901, loss = 2.55224e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.537\n",
      "INFO:tensorflow:step = 26001, loss = 2.94616e-05 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.817\n",
      "INFO:tensorflow:step = 26101, loss = 6.31872e-05 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.835\n",
      "INFO:tensorflow:step = 26201, loss = 7.98585e-05 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.431\n",
      "INFO:tensorflow:step = 26301, loss = 4.68763e-05 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.355\n",
      "INFO:tensorflow:step = 26401, loss = 2.49945e-05 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.3\n",
      "INFO:tensorflow:step = 26501, loss = 0.000144205 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.357\n",
      "INFO:tensorflow:step = 26601, loss = 2.8821e-05 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.214\n",
      "INFO:tensorflow:step = 26701, loss = 3.38602e-05 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.648\n",
      "INFO:tensorflow:step = 26801, loss = 4.95811e-05 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.802\n",
      "INFO:tensorflow:step = 26901, loss = 3.29422e-05 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.196\n",
      "INFO:tensorflow:step = 27001, loss = 4.26859e-05 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.805\n",
      "INFO:tensorflow:step = 27101, loss = 1.59492e-05 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.211\n",
      "INFO:tensorflow:step = 27201, loss = 1.08951e-05 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.939\n",
      "INFO:tensorflow:step = 27301, loss = 2.03488e-05 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.297\n",
      "INFO:tensorflow:step = 27401, loss = 2.66998e-05 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.081\n",
      "INFO:tensorflow:step = 27501, loss = 2.85641e-05 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.603\n",
      "INFO:tensorflow:step = 27601, loss = 2.9843e-05 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.354\n",
      "INFO:tensorflow:step = 27701, loss = 9.66139e-05 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.539\n",
      "INFO:tensorflow:step = 27801, loss = 1.1353e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "INFO:tensorflow:step = 27901, loss = 7.06387e-05 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.557\n",
      "INFO:tensorflow:step = 28001, loss = 0.000128241 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:step = 28101, loss = 3.72053e-05 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.262\n",
      "INFO:tensorflow:step = 28201, loss = 2.8001e-05 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.356\n",
      "INFO:tensorflow:step = 28301, loss = 3.24904e-05 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.472\n",
      "INFO:tensorflow:step = 28401, loss = 6.11929e-05 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.239\n",
      "INFO:tensorflow:step = 28501, loss = 7.15377e-05 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.432\n",
      "INFO:tensorflow:step = 28601, loss = 3.74433e-05 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.351\n",
      "INFO:tensorflow:step = 28701, loss = 3.0653e-05 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.775\n",
      "INFO:tensorflow:step = 28801, loss = 2.47498e-05 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.422\n",
      "INFO:tensorflow:step = 28901, loss = 5.98092e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.748\n",
      "INFO:tensorflow:step = 29001, loss = 0.000130719 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.585\n",
      "INFO:tensorflow:step = 29101, loss = 4.41405e-05 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.043\n",
      "INFO:tensorflow:step = 29201, loss = 3.9479e-05 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.214\n",
      "INFO:tensorflow:step = 29301, loss = 3.66048e-05 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.782\n",
      "INFO:tensorflow:step = 29401, loss = 6.16107e-05 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.938\n",
      "INFO:tensorflow:step = 29501, loss = 1.79922e-05 (0.246 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 459.6\n",
      "INFO:tensorflow:step = 29601, loss = 1.86317e-05 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.347\n",
      "INFO:tensorflow:step = 29701, loss = 2.4959e-05 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.348\n",
      "INFO:tensorflow:step = 29801, loss = 2.60203e-05 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.113\n",
      "INFO:tensorflow:step = 29901, loss = 5.90728e-05 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.781\n",
      "INFO:tensorflow:step = 30001, loss = 2.14614e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:step = 30101, loss = 6.88266e-05 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.077\n",
      "INFO:tensorflow:step = 30201, loss = 6.48012e-06 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.209\n",
      "INFO:tensorflow:step = 30301, loss = 2.40528e-05 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.672\n",
      "INFO:tensorflow:step = 30401, loss = 7.44834e-05 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.567\n",
      "INFO:tensorflow:step = 30501, loss = 5.7814e-05 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.892\n",
      "INFO:tensorflow:step = 30601, loss = 8.69968e-06 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.603\n",
      "INFO:tensorflow:step = 30701, loss = 2.49321e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.154\n",
      "INFO:tensorflow:step = 30801, loss = 2.2736e-05 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.655\n",
      "INFO:tensorflow:step = 30901, loss = 1.82465e-05 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.818\n",
      "INFO:tensorflow:step = 31001, loss = 9.36237e-05 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.733\n",
      "INFO:tensorflow:step = 31101, loss = 1.21087e-05 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.17\n",
      "INFO:tensorflow:step = 31201, loss = 0.000197811 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.764\n",
      "INFO:tensorflow:step = 31301, loss = 4.80753e-05 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.051\n",
      "INFO:tensorflow:step = 31401, loss = 4.7503e-05 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.286\n",
      "INFO:tensorflow:step = 31501, loss = 0.000122302 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.877\n",
      "INFO:tensorflow:step = 31601, loss = 1.67473e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.522\n",
      "INFO:tensorflow:step = 31701, loss = 0.000114446 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.125\n",
      "INFO:tensorflow:step = 31801, loss = 3.65064e-05 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.667\n",
      "INFO:tensorflow:step = 31901, loss = 2.88474e-05 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.929\n",
      "INFO:tensorflow:step = 32001, loss = 2.22907e-05 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.354\n",
      "INFO:tensorflow:step = 32101, loss = 3.90623e-05 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.491\n",
      "INFO:tensorflow:step = 32201, loss = 5.78941e-05 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.267\n",
      "INFO:tensorflow:step = 32301, loss = 1.31172e-05 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.186\n",
      "INFO:tensorflow:step = 32401, loss = 3.77253e-05 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.237\n",
      "INFO:tensorflow:step = 32501, loss = 2.17414e-05 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.734\n",
      "INFO:tensorflow:step = 32601, loss = 2.32828e-05 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.509\n",
      "INFO:tensorflow:step = 32701, loss = 6.8523e-05 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.423\n",
      "INFO:tensorflow:step = 32801, loss = 1.64877e-05 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.215\n",
      "INFO:tensorflow:step = 32901, loss = 2.74332e-05 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.767\n",
      "INFO:tensorflow:step = 33001, loss = 6.75272e-05 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.879\n",
      "INFO:tensorflow:step = 33101, loss = 9.64338e-05 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.492\n",
      "INFO:tensorflow:step = 33201, loss = 2.8093e-05 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.657\n",
      "INFO:tensorflow:step = 33301, loss = 0.000101972 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.569\n",
      "INFO:tensorflow:step = 33401, loss = 3.40532e-05 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.879\n",
      "INFO:tensorflow:step = 33501, loss = 1.74609e-05 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.67\n",
      "INFO:tensorflow:step = 33601, loss = 2.06527e-05 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.507\n",
      "INFO:tensorflow:step = 33701, loss = 7.02339e-05 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.174\n",
      "INFO:tensorflow:step = 33801, loss = 7.01454e-05 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.286\n",
      "INFO:tensorflow:step = 33901, loss = 6.06656e-05 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.672\n",
      "INFO:tensorflow:step = 34001, loss = 5.47846e-05 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.3\n",
      "INFO:tensorflow:step = 34101, loss = 3.47578e-05 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.508\n",
      "INFO:tensorflow:step = 34201, loss = 2.34682e-05 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.733\n",
      "INFO:tensorflow:step = 34301, loss = 0.000134338 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.893\n",
      "INFO:tensorflow:step = 34401, loss = 7.71975e-06 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.604\n",
      "INFO:tensorflow:step = 34501, loss = 2.67107e-05 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.176\n",
      "INFO:tensorflow:step = 34601, loss = 1.04281e-05 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.296\n",
      "INFO:tensorflow:step = 34701, loss = 0.000118727 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.338\n",
      "INFO:tensorflow:step = 34801, loss = 2.33962e-05 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.941\n",
      "INFO:tensorflow:step = 34901, loss = 1.08666e-05 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.881\n",
      "INFO:tensorflow:step = 35001, loss = 9.13113e-06 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.187\n",
      "INFO:tensorflow:step = 35101, loss = 1.51624e-05 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.521\n",
      "INFO:tensorflow:step = 35201, loss = 2.45072e-05 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.08\n",
      "INFO:tensorflow:step = 35301, loss = 5.01407e-05 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.114\n",
      "INFO:tensorflow:step = 35401, loss = 3.30985e-05 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.537\n",
      "INFO:tensorflow:step = 35501, loss = 6.06764e-06 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.618\n",
      "INFO:tensorflow:step = 35601, loss = 4.32132e-05 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.787\n",
      "INFO:tensorflow:step = 35701, loss = 1.32216e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.209\n",
      "INFO:tensorflow:step = 35801, loss = 9.92729e-06 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.355\n",
      "INFO:tensorflow:step = 35901, loss = 3.03981e-05 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.78\n",
      "INFO:tensorflow:step = 36001, loss = 1.62614e-05 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.668\n",
      "INFO:tensorflow:step = 36101, loss = 4.4442e-05 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.497\n",
      "INFO:tensorflow:step = 36201, loss = 1.21084e-05 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.777\n",
      "INFO:tensorflow:step = 36301, loss = 8.08841e-05 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.406\n",
      "INFO:tensorflow:step = 36401, loss = 1.2159e-05 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.335\n",
      "INFO:tensorflow:step = 36501, loss = 3.20589e-05 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.147\n",
      "INFO:tensorflow:step = 36601, loss = 2.02303e-05 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.807\n",
      "INFO:tensorflow:step = 36701, loss = 0.000109789 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.357\n",
      "INFO:tensorflow:step = 36801, loss = 6.79222e-06 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.488\n",
      "INFO:tensorflow:step = 36901, loss = 1.62821e-05 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.218\n",
      "INFO:tensorflow:step = 37001, loss = 5.38557e-05 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.425\n",
      "INFO:tensorflow:step = 37101, loss = 0.000114488 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.219\n",
      "INFO:tensorflow:step = 37201, loss = 5.976e-05 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.241\n",
      "INFO:tensorflow:step = 37301, loss = 1.21087e-05 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.496\n",
      "INFO:tensorflow:step = 37401, loss = 4.09572e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.448\n",
      "INFO:tensorflow:step = 37501, loss = 7.39375e-05 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.707\n",
      "INFO:tensorflow:step = 37601, loss = 2.1497e-05 (0.200 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 459.602\n",
      "INFO:tensorflow:step = 37701, loss = 1.03636e-05 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.489\n",
      "INFO:tensorflow:step = 37801, loss = 0.000107745 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 443.265\n",
      "INFO:tensorflow:step = 37901, loss = 8.69446e-05 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.176\n",
      "INFO:tensorflow:step = 38001, loss = 1.36866e-05 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.665\n",
      "INFO:tensorflow:step = 38101, loss = 1.53964e-05 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.878\n",
      "INFO:tensorflow:step = 38201, loss = 2.09805e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.152\n",
      "INFO:tensorflow:step = 38301, loss = 2.22999e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.409\n",
      "INFO:tensorflow:step = 38401, loss = 1.46e-05 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.303\n",
      "INFO:tensorflow:step = 38501, loss = 0.000146781 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.489\n",
      "INFO:tensorflow:step = 38601, loss = 3.28799e-05 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.123\n",
      "INFO:tensorflow:step = 38701, loss = 6.01676e-05 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.301\n",
      "INFO:tensorflow:step = 38801, loss = 1.58324e-05 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.679\n",
      "INFO:tensorflow:step = 38901, loss = 3.73974e-05 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.688\n",
      "INFO:tensorflow:step = 39001, loss = 1.08643e-05 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.995\n",
      "INFO:tensorflow:step = 39101, loss = 3.55024e-05 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.771\n",
      "INFO:tensorflow:step = 39201, loss = 3.48821e-05 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.536\n",
      "INFO:tensorflow:step = 39301, loss = 5.49278e-05 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.941\n",
      "INFO:tensorflow:step = 39401, loss = 3.83998e-05 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.873\n",
      "INFO:tensorflow:step = 39501, loss = 9.23628e-05 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.362\n",
      "INFO:tensorflow:step = 39601, loss = 1.19585e-05 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.432\n",
      "INFO:tensorflow:step = 39701, loss = 1.01657e-05 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.831\n",
      "INFO:tensorflow:step = 39801, loss = 8.42162e-05 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.07\n",
      "INFO:tensorflow:step = 39901, loss = 1.54748e-05 (0.256 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\przem85\\AppData\\Local\\Temp\\tmpoga7q041\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.98599e-05.\n",
      "WARNING:tensorflow:From C:\\Users\\przem85\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:381: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From C:\\Users\\przem85\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:454: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\przem85\\AppData\\Local\\Temp\\tmpoga7q041\\model.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=10,\n",
    "    feature_columns=feature_columns)\n",
    "\n",
    "dnn_clf.fit(x=data_X, y=data_y, batch_size=50, steps=40000)\n",
    "y_pred = list(dnn_clf.predict(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad\n",
    "Narysuj wynik powyższego programu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\przem85\\AppData\\Local\\Temp\\tmpoga7q041\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl+bmTiBndpgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20dd95a3e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Możemy też sami zbudować sieć "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy sieć typu fully_connected z funkcją aktywacji relu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons=2\n",
    "with tf.name_scope(\"linear_model\"):\n",
    "    n_inputs = int(X.get_shape()[1])\n",
    "    stddev = 2 / np.sqrt(n_inputs)\n",
    "\n",
    "    init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "\n",
    "    W = tf.Variable(init, name=\"weights\")\n",
    "    b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "    z = tf.matmul(X, W) + b\n",
    "    tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        if activation==\"relu\":\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=\"relu\")\n",
    "    logits = neuron_layer(hidden2, n_outputs, \"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")   \n",
    "    \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.94\n",
      "1 Train accuracy: 0.96\n",
      "2 Train accuracy: 0.9\n",
      "3 Train accuracy: 0.92\n",
      "4 Train accuracy: 0.98\n",
      "5 Train accuracy: 0.96\n",
      "6 Train accuracy: 0.96\n",
      "7 Train accuracy: 0.9\n",
      "8 Train accuracy: 0.9\n",
      "9 Train accuracy: 1.0\n",
      "10 Train accuracy: 0.96\n",
      "11 Train accuracy: 0.98\n",
      "12 Train accuracy: 0.94\n",
      "13 Train accuracy: 1.0\n",
      "14 Train accuracy: 0.98\n",
      "15 Train accuracy: 0.98\n",
      "16 Train accuracy: 1.0\n",
      "17 Train accuracy: 0.98\n",
      "18 Train accuracy: 1.0\n",
      "19 Train accuracy: 1.0\n",
      "20 Train accuracy: 1.0\n",
      "21 Train accuracy: 1.0\n",
      "22 Train accuracy: 1.0\n",
      "23 Train accuracy: 1.0\n",
      "24 Train accuracy: 1.0\n",
      "25 Train accuracy: 1.0\n",
      "26 Train accuracy: 1.0\n",
      "27 Train accuracy: 1.0\n",
      "28 Train accuracy: 1.0\n",
      "29 Train accuracy: 1.0\n",
      "30 Train accuracy: 1.0\n",
      "31 Train accuracy: 1.0\n",
      "32 Train accuracy: 1.0\n",
      "33 Train accuracy: 1.0\n",
      "34 Train accuracy: 1.0\n",
      "35 Train accuracy: 1.0\n",
      "36 Train accuracy: 1.0\n",
      "37 Train accuracy: 1.0\n",
      "38 Train accuracy: 1.0\n",
      "39 Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size, X,  y):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(X.shape[0], size=batch_size)  # not shown\n",
    "    X_batch = X[indices] # not shown\n",
    "    y_batch = y[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size, data_X, data_y)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        #acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,y: mnist.validation.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train)#, \"Val accuracy:\", acc_val)\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "[[-4.50067568  3.48027682]\n",
      " [ 5.42456865 -6.61987209]\n",
      " [-6.28870821  4.14164305]\n",
      " ..., \n",
      " [ 2.17544627 -5.43836355]\n",
      " [ 3.57405996 -3.74473214]\n",
      " [-1.88609052  2.811836  ]]\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = data_X\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    print(Z)\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(Z.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Narysuj wynik powyższego programu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2MHPd5H/DvM3u3txL3eNflnd4okaJLvVqw24KQnEQ6\nMDWVSKpSOkQSSRBaxzZAq6GaBijQ6gVojAC1DBQtEFV0lEMiuAZUSwYqhaotRRWLGseitSracFzJ\nFF2CsihSEl+0uSOX9N7d7jz9Y3Z2Z+dmb3fnfXa+H+DAu73lznB59zy/1+cnqgoiIsofI+kbICKi\nZDABEBHlFBMAEVFOMQEQEeUUEwARUU4xARAR5RQTABFRTjEBEBHlFBMAEVFOjSV9A+uZKZf1+k2b\nkr4NIqLM+NGJE+dUdXaQ56Y6AVy/aRMOP/lk0rdBRJQZ8tWvvj/oczkERESUU0wAREQ5xQRARJRT\nTABERDnFBEBElFNMAEREOcUEQESUU0wAREQ5xQRARJRTTABERDnFBEBElFNMAEREOcUEQESUU0wA\nREQ5xQRARJRTTABERDnFBEBElFNMAEREOcUEQESUU0wAREQ5xQRARJRTTABERDkVSgIQkedE5IyI\nvN3j+ztFZElEftL6+DdhXJeIiPwbC+l1vgXgGQDfXuc5h1T1/pCuR0REAYXSA1DVBQDVMF6LiIji\nEeccwK+KyE9F5DUR+XSM1yUiIg9hDQH182MAW1S1JiL3AfgrADd4PVFE9gLYCwBbKpWYbo+IKH9i\n6QGo6nlVrbU+fxXAuIjM9HjuvKruUNUds+VyHLdHRJRLsSQAEblKRKT1+e2t634Sx7WJiMhbKENA\nIvIdADsBzIjISQB/DGAcAFT1WQC/A+CfiUgDwC8BPKiqGsa1iYjIn1ASgKo+1Of7z8BaJkpERCnB\nncBERDnFBEBElFNMAEREOcUEQESUU0wAREQ5xQRARDQqFhaGejoTABHRKBgy+ANMAERE2ecj+ANM\nAERE2eYz+ANMAERE2eUK/vNWIeWBMQEQEWVRwOAPMAEQEWVPj+C/gLmhXoYJgIgoSxYWgLlWoJ+b\ns4L/3NzQwR+I70QwIiIKwtnqX1iwAv9Cq9Xvcx6YPQAiorQLacjHjQmAiCjNIgr+AIeAaETse+pN\nLF5YWfP49GQR+x+/I4E7IgrBkMF/bg54/vnBX54JgCI3bHB2Pr+6tAyzdXqoIYLK1ITn3128sIKl\n2gqaze6TRs8t1rHvqTeZBChZATZr2QYJ/sNiAqDILV5YwVR53PPxfs+vLi1jfMwaqWw2tf344oWV\nrkRxbrEO0/S+/s/fP4+7H3kDADBRNPC9pz/PHgPFx7lqx8/fRTTBH2ACoBD1CqrVpWXPBNDr75xb\nrGOptoItV21Y93rHT15of94r+Lstr5hr/q6t0VScqdbx8BOHuh5nUiBfXKt2/Ioq+ANMABSiXsMw\njabixMcXPQO6VyA2zU6gdjvx8UU0mwpTdeCg77bvqTdhqrZ7Fs77BLAmWfXqqRD15A74PqP0/MLN\n1stFEPwBJgAKWbOpKBSk67FGU9ckBdt6gdj+3P11UD9//zyATpKZKHZf304yznt8+IlD7AnQYLwm\nbgNMAUQV/IGQEoCIPAfgfgBnVPU2j+8LgD8FcB+ASwB+X1V/HMa1KTnu4Rt7HL5pKorjRlcrvtFU\n/L8Tndb+WEHarfherf33TtWiu3kH9/W97qe6tIzq0nIs90MZFsGSzbm5zjRCkOkEL2H1AL4F4BkA\n3+7x/XsB3ND6uAPAn7X+pAxzT+5Wl5ZhQqEDNNIbTYVI/+ekhX0v9mSyzWh1HgwRfOraSfYQ8qxP\n8PcTuBcWOi8bdvAHQkoAqrogItev85TdAL6tqgrghyIyLSJXq+pHYVyfknfi44tdAbtXq95pkESR\nViLW/TtXKHGuIMcGaPkHXQkadvAH4psD2AzgA8fXJ1uPrUkAIrIXsN69LZVKLDdHwTVbLfosB/Vh\n2P9OZ6I7t1hvzxUA3pPHnEcYQQMO+/jtAfj9u4NI3SSwqs4DmAeAHVu35iScjAb3uH/eGCKYKo+3\nA/8wex8oo4YY8/fbA4gq+APxJYBTAK5zfH1t6zHKGHvi90y1DgDtP4F0jdknwV7uOlUuJn0rFAfX\nzOz8ws1WWeaFaCduwxRXAngFwKMi8gKsyd8ljv9nkz3x6wz81LG8Ynomx7FCnxlvyo4ByjJHOXEb\nprCWgX4HwE4AMyJyEsAfAxgHAFV9FsCrsJaAHoO1DPRLYVyXwtVrJ+9SbaXdqj23WOdySB+cvSPu\nKcgwH8XZ0iysVUAP9fm+AtgXxrUoOl41e459cAGq3a1ZE/ke6gnqTJVJNJNGLPgDKZwEpnSxV7vY\na/bTsMrHa7VRvxVI9hBMWuYpGk3F3Y+8gbFCp8IpwFVCqTWCwR9gAqAe3OUQ0hD4bV73UhzvrMff\ntrmMpdoqnv/6XWue9/ATh9r1itKSDJy9Lq4SSqERDf4AEwD1YNf0STpIXlEpAbBaxs4hKjtB2fe3\n2rCWnxoiWKqtttfiuzkfP7dYhyHJ/xspxUY4+ANMABSzG7ZMArAC+GrDxMx0ac2KIru8wviY0dWK\nd5ZpdlYW7dXa9+IcXnn4iUNdrW9nrSK3qIbAGk3Fe6dqKBSkb/lritmIB3+ACYAcpieLOH7yQrtI\nW5Qt4y1XbRgqcEfB7lXYDMPqQRQKsu6GtrGQe0Z2xdP3TtVgqvIEszTIQfAHmAAI3cs/TVUYIqlc\n6eMO2M7H/XAHWWePwN0biGMOxE4qP3//PJeKJmmdDV5eshr8ASaAXLMDv/s4xaiCf7/qn/1EHQyd\nCcbdyrdXETVNbZ9RHCVnSQmKyQAbvJyyHPhtTAA5Zk+q2mWcw2KP89veO1VrL3Vcqq22H/fbco/K\nej0Cp6XaKqpLy5EOkdk9kHv3HWy/d+wRRCgnQz5uTAA54z5IPYqSDs4gDyCzdfL7DTmd/dt6LEND\ndhJijyAiOQ3+ABPAyHOXd4iqhs9E0UCzqahMTSQ6sRum9ZLWw08cwvbrrJ7Oe6dqXEqaVTkO/gAT\nwMhzl3eIKgF4nQUciSCnaoT42+vsHUQ5J+BcJsoqo+sIetoK8hf8ASYACsm2zWUAa4d/QhXkdAz7\nbL2QfoudvYN9T72JYx+c75pID1OhIF27ssklyP9r62cqj8EfYAKgkNiBP5KJXXfrLkhrL4L6vPsf\nv6NdYiKKA3Hs1zxTreM3/+ANnj9sc63a8SuvwR9gAqAhTRSNrq8jH/d3/2IHbOm1Pw/5t9qZ+KpL\ny+1hIUOkvbEuDKZpLdM99kHO9wqE9HMxv3Cz9XI5DP4AE0BunPj4YiitU7vmjs0QiW45p9cEne+G\n3s3Ya5002nntEH+7+00Yh907MM0c7xUI9eciv8EfYAIYeXZ5h6CrVAwD2H7dxvhamz1WZwTpAcxj\nb6RJoBc7Qbo33AXlPn6y14E+I9VLCPHnwjmllIXjG6PABDDi9j9+B+7ddzDQa6Ql+PfakTmYOcwh\nmSRgv292gA5rE9nyitl1sIzXgT724yMhkp+L7BzfGAUmgBwIskzRPrAkFcG/h6/94R5sLFfXPH6+\nVsHXnn6p89LOJDD3buzNPq9KpEH3EDSainv3HcSnrp3s/+Qs8/FzMay8BX+ACWBkhN26tJmq8ZVs\nGPCX3P2LOjtTRX2lsubltm4+iv1/shMAsOzY/nC+VsH8038E4GbsXZjvvnYGo0CjqaPTyvfi8+cC\nAHbftQelibWNg/pyBQcOvZTl//ZQMAGMCLv7H9ZGr7GCtDcfxdL6H6KF514A8oU7gdrFtS9ZmTRx\n7pO1iWFjudrdG0hgXsAW1qE79uE2XkNAmRbg5wIAvnBndc3PwDVXHMPlG0/jC3fuxBfuBCasM4fa\nSSFPmACoi322bqybjwJux58oAWqsfZ4IUG6NjNQ8znpJQxJwHgKz3oE0/XSWh15ol6jIvHXKMg86\ncev1szE21gRgQA0rMdRbnSevnsKoCyUBiMg9AP4UQAHAX6jqN1zf3wngAID3Wg+9pKp/Esa1yVJd\nWu6aEPTLni5oNjXe4Z+u32i0/1zvF93u3m8oncblE2fbj5tawGJte9fLlyfTlQR6FZoLSnXtbuy0\nVV3ta4CyzF4Tt17DPRtKp1EqVtf8PJAlcAIQkQKA/QDuBnASwFsi8oqq/sz11EOqen/Q65E3UxXj\nY0bg4YSxgnSVdUjT8sGv/eEezM50fsE3lE5D1YCIiabZGfowpOn599OUBLze17sfeSO018/s0s8h\ne4P//slO0Ld/HoBOI+DyibM9fx4onB7A7QCOqepxABCRFwDsBuBOABSyrpO8TERShiBNNpatyd7p\n8jEY0oS0PgBgrNA997Fp4xGINFGZPNrVIyhPAvB4m9IwHBTWUZNLtYxOCPsYCixNdBYAXD5xFqYW\nAFiNgOnyMRiG1RuamXo7qrvONI+R06FtBvCB4+uTrcfcflVEfioir4nIp3u9mIjsFZHDInL4bK0W\nwu2NJrsAWVhDP1kyVqi3f7HdGs0SAGm1BAWGsYqxQh2bNh5BZfIoSsUqVNZODAOdQNPeXNT+RvBK\nk4OoTE0EPjUNyGhDIIKyzOu3/GOoXJsBYSSAQfwYwBZV/QyA/wjgr3o9UVXnVXWHqu6YLZdjur3s\nWbyw0j7A3C7DHEbwMFWxVFvFUm01e2PHbQpTC2g0J9BolmCa4/jk/C24tDyLFw/+AAcOvdQzgCSZ\nBKYni5j9OyUYRucISr8y1SgIIfjbrf2xQr3dQOg0EgQKAdofAKBdjYJSsYr6snfDYJSFMQR0CsB1\njq+vbT3WpqrnHZ+/KiLfFJEZVT0XwvWpJYyy9DPTpUwf6GIPBY0VnAFQMV0+tmavgD2x7JbUcJA9\nZu/cJNY01df/a6Op2SgWF1LL32rtC+B5tKl6tvc/OX8LSsUqXjz4g0HvduSE0QN4C8ANIrJNRIoA\nHgTwivMJInKViNU+FZHbW9f9JIRrE4CV1WBdfsNAu9WZ3Va/mzo+rMSwoXQau+/a0/WsublOUHH+\nuQDrG/PY290bsM8ViND0ZLG9kidIUq8uLeP4Sf9LSyMX8rDPsG/VzNQ7XavH8ihwAlDVBoBHAbwO\n4AiA76rqOyLyiIg80nra7wB4W0T+BsDTAB5UjeM01XwI8k6OFQQz0yXMTJdQmZrA4oUVPPzEIex7\n6s3wbjAk52sVVCaP+v77qkbPtd7O3oDzzySGhPY/fgee//pdeG3/LlxRKWGiaGCsIEMPCzWaikZT\nU/l/GVbwry9XUCpWYRirkKFTgEIkg/MlIQplDkBVX1XVG1X176rqv2099qyqPtv6/BlV/bSqflZV\nP6eq/yuM6+ZdGJu1TFVMlcfXfKSxtICzrk8U0jgvAHSO2/R75Gbq/i+dQ2mtXhbm5ny1/A8ceinX\nQzhBxTUJTCGbnixiqlxEZWoi0OsYYcwcxyhIi80wVvt2+dOaBIJIzYSwc/istcFrfuFmLGDO8210\nDs9RNJgAMsoeJggyYXvj1o2BE0gy/CQtQaNZGiiBpDUJ+J3rsSeEEx0KimCZZxhEmmvmhfKECSCn\nDMMaGji3WMeJjz0qqaWan2EvRaEweEs4LUlgerIIUxXNpr/VQLZEh/UiDv5BArhpjueyBpCNCSDD\n9j31Jh5+4pCvv2tXjjQkxqJvXlwzr+0zWj0mZIMRCLRdKmAQXquD1v9G+PY/fgdmpkvYtrkceG9A\nImJo+QcJ4PbO4bxiAsiwXidADcKeUCwUpGvzV2ybwNzLKV2TgV4xdm4OQwXwblaSEzHxwK6dmer2\n28tCgxzsk4iUDvs45b1IHMtBZ9S+p97EucW67wm+ZlPx3qkaCq1loLFu/upxqPcg1R6DUjVQX6mk\nvtvvdb5vmOcJRy4DwZ+YADLLWQpimAJiznr/AOIf/gkQGEoTVVQv3ITK5FGI0fCx7js7XX6v3l1Y\nh/1ELoYxf2cCL1/24XAvQG1MABlkt/5NE0NXj1QNp2aQLyEGhmZzolXuYbh/v9GqEJo39mEzv/kH\nVsnp8TED33v68+FfKKYxf2dZjyAJIK81gGxMABlkt/5NaLtFP6gxV8s/tkNfQgwMphZ8BX8APauI\nZoH9f7dtc9n36WGmaTUAVhsRjCc5T+5B+od9ar+8JvebyJgAMsbZ+geGC/4TRaPrCEIgpkNfQm4V\nLta2ozJ5FIbRwLBJwC4L5mf4aFSE3gv0OsELnf/fQY9vHJZ9LgT5x1VAGXP85AXfk4H2xG+s6/5T\nNhnoLAicJSc+vtiu7fPeqRSdkzHA/6/XhH4YDGkGmtPJ89CPjQkgY8JYCrjaMONZ7hly8LcLf5WK\n1daO3mDvRZqXgtpLP+2PSIZsgko4udv1//06cCja2lJZwCGgjPHb+nef9Rv5ss8IgoPzF/aBXTtR\nKlZ9BIBO0qhsTO9ksHtYzj4jwOZ3DsAWeElpgsG/vpz+ZbxZwR5ARgTZ9QsMv1ookHWqPfba4OXH\nYm07TNPfRjggWGG5XEu45R9OBdAsDgSGjz2AFHNuBnJO/A5r2JVCvnlNBg6wwcsPuxWYxyAexhyO\n4bfpl7I5HT9McxyXlmeTvo1UYA8gxezNQHbNHr9irSDQo05O2OVz7FbgxfqVvl9j0EqQveoS2XWL\nQixYNJBmU5PZy5Fw8P/ifZ/Bl++/pf3hD1v+TkwAOZL9w97D128sOU1VQe3/P1ODVQb1JcHgv/uu\nPXhg106MFeoQMVsffpd/KgxjFeXLPkr1IoC4MAHkhO8u/4grX/Zh3+JwaUgCzvMfZqZL8VYGTbjl\n79z52znl2T+FwDTHOJEMJoDcME2k+rhHv+rLlUATwYBVDiArPYGwmCb6HxLjs2Jr1IJu4ms2s3gI\nUjQ4CZwRwxZ9ywvn0tAv338Lmq1kMEypiLFCve9RkUAnuLl3tS4sWMFwvhUr92K+80TnX4yA3wn+\niaKxfmPAZ8XWNFMIZwBc2ANIMee471S5GKjbn8nDRIakamCsUG/tDRguKg6zmshR7qbrz7h6A/Yp\nYcDwwX+sIJ4lQbqMwEofGkwoCUBE7hGRoyJyTEQe8/i+iMjTre//VET+QRjXHXXOcd/nv34XXtu/\nC1dUSknfVmpdWp6FaY6j0Syh0Yz2fUpySMg+JcwO5sOyS4K8d6qGc4v17mGgFAd/Vcl1DacoBE4A\nIlIAsB/AvQBuBfCQiNzqetq9AG5ofewF8GdBr5tXS7Xhxu8TK/2cA0kmAedZwcMoFKTrwxDpDAOl\nNPiXilXMTL0NkWDBX1pTyIVWRVjWAgpnDuB2AMdU9TgAiMgLAHYD+JnjObsBfFtVFcAPRWRaRK5W\n1Y9CuH6uTJWLQx0MYg8R2Mc+AhjZZaD15Qo2lE77atWINPGV37qx/bVpjqN6/qa+9WKcw0FOC5jD\nHKzNcO05ASC0AfP9j9/R3igYykExKQ3+u+/a0w7Yftg9wYKxiue+dySs2xoZYQwBbQbwgePrk63H\nhn0ODWGYlr1hANuv29geSoq8/HNCDhx6CRfrV6J64SZUL9wU6LUMYxWbpo4MtFY8qZ6APUQ4jGZT\nuz4KBQHq3QkkLcEfsJaA+j8H2qoYakgz0GuMstS9KyKyV0QOi8jhs7UUlb3NmImigYmigbHWmb+j\nGvSjI1A1Bl4rnpVlots2l7s+tpS7h1XSFPxtQQ7xubQ8i0vLs6ieD9YgGFVhDAGdAnCd4+trW48N\n+xwAgKrOA1afecfWrZzxabG7++cWrdZav9UfsZ/4lRLdlSIFwbcNDS6p4SDD6Jz0Baz92bA3Aa6p\nJeVqYKUl+Ntn/l4+cTZQ8OeJX/2F0QN4C8ANIrJNRIoAHgTwius5rwD4p63VQJ8DsMTx/+HYdYEG\nrQlkt/Dy1vq3awS9ePAH+Mv/ejTAJjGrZMCG0umhSgakoScg0kkGV1RKeP2bd+P1b96NG7du7Jwx\ncO4CljCBpbpienZjKjZ42brP/PW7ioGrHwYRuAegqg0ReRTA6wAKAJ5T1XdE5JHW958F8CqA+wAc\nA3AJwJeCXjev+m0IG2ut7iDLpeVZlC/7sLUJaPjewDDDQLZBNoztnXt3zRm6vqnrT6d6vf36+3/N\n+Y0JAIp5/HPrXhPe4OVu9Qc56B2w/t+4yqe/UHYCq+qrsIK887FnHZ8rgH1hXCvvtly1ASc+vtg1\nxDMzXUJ1aRkAUJmytrmP+oqfQdWXKyhf9qHv9ePWucP+9NowhnawvRl7F+Y7T/bJePEgzKZ6/wtL\nJWDONVGcokPb7cC/oXQaqkagIR/buaXbUCpWeeLXAFgKIoOcuzhjOd0rww4cegkP7NqJ+koFM1Nv\n+3gFxYbSaTywa2f7EbtshLumfH25siboDDwvEKAX8Kkp4PgiYLrH/gWYxrLna6ch+AOd4Z7LJ87C\n1AIMBE0A7P0OgwmAqA8Rs6tWkN1KLRWrWKxtbz/ea6hooCQw967v+9s/ZLC2zzFIOvhHocFCb0Nh\nAsiI6cmiZ+GuvA/xDMM0x30OMSgMowGFVUnSaqUKjCFq0vdNAvbhMjEZxeAPAPWVCkrFKsf/B8QE\nkBF5WskTtnAOEVcI4OMQ+o51k0CMgbfXaFOSwd8wGjDgf74FsBI8l30OhwmARl53yeibAteUCaJn\nEkj4+IAogr89wWu7fOIsREyoGu35kw2l0ygVgyVn0xyHiMnNXj4wAVCuXKxfHXiJoUV9rxDySgJJ\n9gCiunb3en47ATQh0uz6Pxgr+DvesdEswZAmqhdu4qofn5gAKHcazVKgoZwO7Wq9DjPu7E4CcfYA\nnNfO8pj/WKEeednvUccEQLmzWNuOyuTRVgs+vOGg0kQVu+/aM3BL1L1hLA72KY9xBv7p8jGrKFsI\na/ydVAuc9A2ICYByze8OYcAae3YOcQC9l4KuJ4zNwMNeL06GNENa49851tE0x3BpeZaTvgExAVA4\nXFte22vNXTth08IOSEFOiTWM1TWby1QLXZvGAO8NYm5ZHopxc+7uLV/2EQANJfhT+JgAKLghDhNJ\n+gBxe0lofaUSavkBm3uCEwDKl33YTgqDJIOsca/2sd9XGWKfxKDs3pqphdBfO4+YACiYlJ4k1Ysz\n+DoLkImYkQQsmz1UFHw/QjzcQd3mlcC8V/sEW9PvZg/VnVu6rXPdgMtHiQmAgshY8HdzB7IHdu0M\nVDl0Pf7qECXHHdSdj7tdPnHWs1RGmOyBOr+rrsgbEwD5k/Hg31uQWYHBDNO6TiPn/Qc9tGVwikaz\nxEnfkDEB0PBGNvhbq0vEaESaBDZNHUHTHO8qJAeke3jIXsopYrbH+IFoWvtujWYJ9ZUKg38EmABo\nOCMc/OvL1sRw2MM/biJNjBWaqEweBWBNaLqTQdLsYZ1eeyWinC9xW6xt53h/RJgAaHAjHPyBztkB\n9rBGFHMBTnbr2cBqu4XtXkIK9B4aCnMoyf1a1r3Fe6YyxY8JgAYz4sHfZvcCgHiPFrGHV+yJVzsh\nAOg6kMYZ3O2JWudznc8fJhG4J33DqZfUn0LQbE5grFBH7ZfXdA0vAVzuGTUmAFqfR+Ww+YWbrQPE\n15x5m93Ab3P2AtzBxw6yl5ZnQx8Ht1+j12ohOyCXL/sQX/mtG9uPb7jsI6g51nWvY8YqLp84u+Yk\nM3dCcLb6N5ROe0zoRt/6V3PM2incKuVsn95G8WACoN68Wv0LyR8gHgdTC2sOfBEx8cnSLV3HTALx\nL/HU9kolhcD7LGA7kDtb8nbyUC14juHHOa4PCExzDNULVglne4y/19kNXPIZDSYA8paTIR8vvYJN\nWpZpuuclDGN1qFILTXPcdwnmcPSeWUnD+5sngRKAiFQAvAjgegC/APB7qvq3Hs/7BYALAJoAGqq6\nI8h1KWI5Dv6AnyCUrcnScEphD880x7t6ViJmV8uf4he0B/AYgP+uqt8QkcdaX//rHs/9dVU9F/B6\nFLWcB/9BOYcqoqp7M1pkzXLXUrHKtf0JC5oAdgPY2fr8PwH4AXonAEo7Bv+BuSdTN00dCb2w3Cg4\nt3QbKpNH20dAspRDugRNAFeq6ketzz8GcGWP5ymAg2I1k/5cVecDXpfCxuDvm3NSeGbqHfQeDsrW\nUFEYSsUqqudv4th+SvVNACJyEMBVHt960vmFqqr0Pm37TlU9JSJXAHhDRN5VVc8K8SKyF7Ciz5YK\nWwixYPAPzB4SUjXWrGNfrG3Hpo1H8Mn5WzJXFM4/a5UPh3jSrW8CUNVdvb4nIqdF5GpV/UhErgZw\npsdrnGr9eUZEXgZwO9oLCdc8dx7APADs2Lo1X82lJDD4h8Ju4Y7aOnY/u6FNc7x9UDulm9H/Ket6\nBcAXW59/EcAB9xNEZIOITNqfA/gNAHlpBqWbc/H+3JwV/OfmsIA558PtPxn8+6svW2fUuj+cvYIs\n8doNrbHukaYoBZ0D+AaA74rIVwC8D+D3AEBErgHwF6p6H6x5gZdFxL7ef1bVvw54XQrC2epfWMjV\nBq+o9RrrtnfdmuZ4piaKTXNszf2u3yOQ9vJOTvKmX6AEoKqfAPi8x+MfAriv9flxAJ8Nch0KEYd8\nEuFMDF++/xY0zfE1zykYq3jue0ew+649qGw8GuopZaY5jkvLs0PV+Kn98hoA1kSu5+EwPR5Py4Y5\n6o87gfOEwT8VVI2uMhPOkst27Z5Ly7Nd5xe72Wvo7TmHyuTRdgVTwBq6aTQnYEgTl5Zn25OxX/pH\nn25dc221T9Mch4iJi/UrGcRzggkgLxj8U6N6/ibPQ9RNLXQF+9JEdeDaOKYWYGDVMTqvVpE1V0G7\nS8uznhVERcx20mHgzw8mgDxg8E8Vr7OIe60cGjQYL9a2dwV1O6AD3cmiV6+CgT+fmABGHYP/SHP2\nEJxBvVdAZ5AnJyaAUcbgP/IY0CmIbC5Opv4Y/ImoDyaAUcQNXpnSa/MY19FT1DgENEq4wSuTOIxD\nSWEPYFRwyIeIhsQEMAoY/InIByaArGPwJyKfmACyjMGfiAJgAsgqBn8iCogJIIsY/IkoBEwAWcPg\nT0QhYQLIknU2eHlh8Cei9TABjAivHb5EROthAiAiyikmACKinGICICLKKSYAIqKcCpQAROR3ReQd\nETFFZMeKI/7+AAAFuklEQVQ6z7tHRI6KyDEReSzINYmIKBxBewBvA9iDdrHhtUSkAGA/gHsB3Arg\nIRG5NeB1iYgooEDnAajqEQAQkfWedjuAY6p6vPXcFwDsBvCzINcmIqJg4pgD2AzgA8fXJ1uPERFR\ngvr2AETkIICrPL71pKoeCPuGRGQvYNU32FLhkXhERFHpmwBUdVfAa5wCcJ3j62tbj/W63jyAeQDY\nsXWrBrw2ERH1EMcQ0FsAbhCRbSJSBPAggFdiuC4REa0j6DLQ3xaRkwB+BcD3ReT11uPXiMirAKCq\nDQCPAngdwBEA31XVd4Lddg7ZheBaf84v3GwVgut+mIe9E9HARDW9oyw7tm7Vw08+mfRtJIvln4lo\nCF/9qvxIVXvuy3LiTuA0Y/AnoggxAaQVgz8RRYwJII0Y/IkoBkwAacPgT0QxYQJIEwZ/IooRE0Ba\nMPgTUcyYANKAwZ+IEsAEkDTnzq25OSv4z80x+BNR5AKVg6YAnK3+hQUr8C+0Wv0epysw8BNR2NgD\nSAKHfIgoBZgA4sbgT0QpwQQQJwZ/IkoRJoC4MPgTUcowAcSBwZ+IUogJIGoM/kSUUkwAUWLwJ6IU\nYwKICoM/EaUcN4KFrU/g5/GNRJQW7AGEaYBWv/0UBn8iShoTQFg45ENEGcMEEAYGfyLKICaAoBj8\niSijAiUAEfldEXlHREwR2bHO834hIv9XRH4iIoeDXDNVGPyJKMOCrgJ6G8AeAH8+wHN/XVXPBbxe\nejD4E1HGBUoAqnoEAEQknLvJCgZ/IhoBcc0BKICDIvIjEdm73hNFZK+IHBaRw2drtZhubwgM/kQ0\nIvomABE5KCJve3zsHuI6d6rq3wNwL4B9ItIzLKrqvKruUNUds+XyEJeI2MLCusc3Oh5u/8ngT0Rp\n1ncISFV3Bb2Iqp5q/XlGRF4GcDs8Dz5MqQGOb+QGLyLKmsiHgERkg4hM2p8D+A1Yk8fZwCEfIhpR\nQZeB/raInATwKwC+LyKvtx6/RkRebT3tSgD/U0T+BsD/AfB9Vf3rINeNDYM/EY2woKuAXgbwssfj\nHwK4r/X5cQCfDXKdRDD4E9GI405gLwz+RJQDTABuDP5ElBNMAE4M/kSUI6KqSd9DTyJyFsD7Pb49\nA2B0SksEw/eig+9FB98LS97eh62qOjvIE1OdANYjIodVtWcBujzhe9HB96KD74WF70NvHAIiIsop\nJgAiopzKcgKYT/oGUoTvRQffiw6+Fxa+Dz1kdg6AiIiCyXIPgIiIAshsAhCRfyci74rIT0XkZRGZ\nTvqekjLo0ZyjTETuEZGjInJMRB5L+n6SIiLPicgZEclOwcWIiMh1IvI/RORnrd+Pf5H0PaVNZhMA\ngDcA3KaqnwHwcwCPJ3w/SbKP5sxOie0QiUgBwH5Y503cCuAhEbk12btKzLcA3JP0TaREA8C/VNVb\nAXwO1lkkef258JTZBKCq/01VG60vfwjg2iTvJ0mqekRVjyZ9Hwm6HcAxVT2uqisAXgAwzIFFI0NV\nFwBUk76PNFDVj1T1x63PLwA4AmBzsneVLplNAC5fBvBa0jdBidkM4APH1yfBX3RyEJHrAfx9AG8m\neyfpEqgcdNRE5CCAqzy+9aSqHmg950lYXb3n47y3uA3yXhDRWiJSBvBfAPyRqp5P+n7SJNUJoN9x\nlCLy+wDuB/B5HfH1rGEczTnCTgG4zvH1ta3HKOdEZBxW8H9eVV9K+n7SJrNDQCJyD4B/BeAfq+ql\npO+HEvUWgBtEZJuIFAE8COCVhO+JEiYiAuAvARxR1f+Q9P2kUWYTAIBnAEwCeENEfiIizyZ9Q0np\ndTRnXrQWAzwK4HVYE33fVdV3kr2rZIjIdwD8bwA3ichJEflK0veUoF8D8E8A/MNWjPiJiNyX9E2l\nCXcCExHlVJZ7AEREFAATABFRTjEBEBHlFBMAEVFOMQEQEeUUEwARUU4xARAR5RQTABFRTv1/Oj5e\n6UQDz7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20dd96f9b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast samemu implementwać wartwę możmy użyć funkcji fully_connected\n",
    "\n",
    "```python\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
    "    logits = fully_connected(hidden2, n_outputs, scope=\"outputs\",\n",
    "    activation_fn=None)\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Zmodyfikuj powyższy kod tak by wykorzystywał funkcję fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wykonaj lasyfikację za pomoca sieci nuronowej zzawierającej conajmniej 3 warstwy ukryte na danych iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
